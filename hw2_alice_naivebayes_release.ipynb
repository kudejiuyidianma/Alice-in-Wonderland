{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3', 'contents', 'chapter', 'i', 'down', 'the', 'rabbit', 'chapter', 'ii', 'the', 'pool', 'of', 'tears', 'chapter']\n",
      "corpus len:  25320\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "f = open('alice_in_wonderland.txt','r')\n",
    "while(1):\n",
    "    line =  f.readline()\n",
    "    if len(line) == 0: break\n",
    "    corpus.extend(line.split())\n",
    "        \n",
    "f.close()\n",
    "corpus = ' '.join(corpus)\n",
    "\n",
    "def clean_word(word):\n",
    "    word = word.lower()\n",
    "    for punctuation in ['\"',\"'\",'.',',','-','?','!',';',':','â€”','(',')','[',']']:\n",
    "        word = word.split(punctuation)[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "\n",
    "corpus = [clean_word(word) for word in corpus.split()]\n",
    "corpus = [word for word in corpus if len(word) > 0]\n",
    "print(corpus[:25])\n",
    "D = len(corpus)\n",
    "print('corpus len: ',D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word list size (number of distinct words):  2501\n"
     ]
    }
   ],
   "source": [
    "tokenize = {}\n",
    "wordlist = []\n",
    "token = 0\n",
    "for word in corpus:\n",
    "    if word not in tokenize.keys():\n",
    "        tokenize[word] = token\n",
    "        wordlist.append(word)\n",
    "        token += 1\n",
    "    \n",
    "V = len(wordlist)\n",
    "print('word list size (number of distinct words): ', V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [9. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# bin how many times a word follows another word\n",
    "counts_2gram = np.zeros((V,V))\n",
    "for i in range(1,len(corpus)):\n",
    "    token_i = tokenize[corpus[i]]\n",
    "    token_im1 = tokenize[corpus[i-1]]\n",
    "    counts_2gram[token_i,token_im1] += 1\n",
    "print(counts_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "posterior_1word = np.zeros((V, V))\n",
    "prior = np.zeros(V)\n",
    "\n",
    "row_totals = counts_2gram.sum(axis=1)\n",
    "count = np.zeros(V)\n",
    "for word in corpus:\n",
    "    x = tokenize[word]\n",
    "    count[x] += 1\n",
    "\n",
    "prior = count/len(corpus)\n",
    "  \n",
    "\n",
    "for i in range (0,len(counts_2gram)):\n",
    "    posterior_1word[i] = counts_2gram[i]/prior[i]\n",
    "\n",
    "x = tokenize['alice']\n",
    "print(posterior_1word[x])\n",
    "likelihood = posterior_1word[x] * prior[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('was', 0.0007109004739336493)\n",
      "('queen', 0.0027646129541864135)\n",
      "('cat', 0.00019747235387045816)\n",
      "('turtle', 0.0022511848341232226)\n"
     ]
    }
   ],
   "source": [
    "#past word as feature\n",
    "\n",
    "posterior_1word = np.zeros((V, V))\n",
    "prior = np.zeros(V)\n",
    "row_totals = counts_2gram.sum(axis=1)\n",
    "count = np.zeros(V)\n",
    "for word in corpus:\n",
    "    x = tokenize[word]\n",
    "    count[x] += 1\n",
    "prior = count/len(corpus)\n",
    "for i in range (0,len(counts_2gram)):\n",
    "    posterior_1word[i] = counts_2gram[i]/row_totals[i]\n",
    "\n",
    "def get_likelihood_2gram(word):\n",
    "    x = tokenize[word]\n",
    "    likelihood = posterior_1word[:,x] * prior\n",
    "    return(likelihood)\n",
    "def pred_2gram(word):\n",
    "    likelihood = get_likelihood_2gram(word)\n",
    "    i = np.argmax(likelihood)\n",
    "    return(wordlist[i], likelihood[i])\n",
    "print(pred_2gram('alice'))\n",
    "print(pred_2gram('the'))\n",
    "# print(pred_2gram('cat'))\n",
    "# print(pred_2gram('turtle'))\n",
    "print(pred_2gram('cheshire'))\n",
    "print(pred_2gram('mock'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_kgram(k):\n",
    "    counts_kgram = np.zeros((V,V))\n",
    "    for i in range(1, len(corpus)):\n",
    "        token_i = tokenize[corpus[i]]\n",
    "        token_imk = tokenize[corpus[i-k]]\n",
    "        counts_kgram[token_i, token_imk] += 1\n",
    "    return counts_kgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_3gram = get_counts_kgram(2)\n",
    "row_totals = counts_2gram.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cards', 0.00011848341232227489)\n",
      "('you', 5.7060000268517644e-06)\n",
      "('up', 2.1392838335966295e-05)\n",
      "('miles', 1.3164823591363875e-05)\n"
     ]
    }
   ],
   "source": [
    "#past 2 words as features\n",
    "\n",
    "posterior_2words = np.zeros((V, V))\n",
    "for i in range (0,len(counts_3gram)):\n",
    "    posterior_2words[i] = counts_3gram[i]/row_totals[i]\n",
    "\n",
    "posterior_2gram = np.vstack([posterior_1word,posterior_2words])\n",
    "\n",
    "def get_likelihood_3gram(word2ago,word1ago):\n",
    "    word1ago_i = tokenize[word1ago]\n",
    "    word2ago_i = tokenize[word2ago]\n",
    "    likelihood_word1 = posterior_1word[:,word1ago_i] * prior\n",
    "    likelihood_word2 = posterior_2words[:,word2ago_i]\n",
    "    likelihood = likelihood_word1 * likelihood_word2\n",
    "    return likelihood\n",
    "def pred_3gram(word2ago,word1ago):\n",
    "    likelihood = get_likelihood_3gram(word2ago,word1ago)\n",
    "    i = np.argmax(likelihood)\n",
    "    return wordlist[i], likelihood[i]\n",
    "print(pred_3gram('pack','of'))\n",
    "print(pred_3gram('the','mad'))\n",
    "print(pred_3gram('she','jumped'))\n",
    "print(pred_3gram('four','thousand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('well', 2.799924290061186e-17)\n",
      "('well', 4.702797636375411e-11)\n",
      "('girl', 1.8513033175355449e-06)\n",
      "('miles', 1.3164823591363875e-05)\n"
     ]
    }
   ],
   "source": [
    "def get_likelihood_kgram(word_lst):\n",
    "    counts = np.zeros(V)\n",
    "    prior = np.zeros(V)\n",
    "    for word in corpus:\n",
    "        x = tokenize[word]\n",
    "        counts[x] += 1\n",
    "    prior = counts/len(corpus)\n",
    "    word_index_lst = []\n",
    "    for word in word_lst:\n",
    "        word_index_lst.append(tokenize[word])\n",
    "        \n",
    "    likelihood = prior\n",
    "    count = 0\n",
    "    word_index_lst = np.flip(word_index_lst)\n",
    "    for index in word_index_lst:\n",
    "        counts_igram = get_counts_kgram(count+1)\n",
    "        posterior_iwords = np.zeros((V, V))\n",
    "        for i in range (0,len(counts_igram)):\n",
    "            posterior_iwords[i] = counts_igram[i]/row_totals[i]\n",
    "        likelihood *= posterior_iwords[:,index]\n",
    "        count = count + 1\n",
    "    return likelihood\n",
    "def pred_kgram(word_lst):\n",
    "    likelihood = get_likelihood_kgram(word_lst)\n",
    "    i = np.argmax(likelihood)\n",
    "    return wordlist[i], likelihood[i]\n",
    "\n",
    "print(pred_kgram(['before', 'she', 'found', 'herself', 'falling', 'down', 'a', 'very', 'deep']))\n",
    "print(pred_kgram(['falling', 'down', 'a', 'very', 'deep']))\n",
    "print(pred_kgram(['what','an', 'ignorant', 'little']))\n",
    "print(pred_kgram(['four', 'thousand']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mad hatter with this as she could guess she was now about two feet high even then they walked off together alice heard a \n"
     ]
    }
   ],
   "source": [
    "# 4(c)\n",
    "text = ['the','mad','hatter']\n",
    "result = ''\n",
    "for i in range(0,25):\n",
    "    text.append(pred_kgram(text)[0])\n",
    "    result += text.pop(0) + ' '\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mad hatter all this way was a time she said waste it in asking riddles that have no answers you knew time it was \n"
     ]
    }
   ],
   "source": [
    "# 4(d)\n",
    "text = ['the','mad','hatter']\n",
    "result_2 = ''\n",
    "for i in range(0,25):\n",
    "    text.append(random.choices(wordlist,weights=get_likelihood_kgram(text),k=1)[0])\n",
    "    result_2 += text.pop(0) + ' '\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
